{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\npath = '/kaggle/input/assignment-4-data'\ntrain_x_path = path + '/train_x.csv'\ntrain_y_path = path + '/train_y.csv'\ntest_x_path = path + '/non_comp_test_x.csv'\ntest_y_path = path + '/non_comp_test_y.csv'\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-28T12:43:47.827776Z","iopub.execute_input":"2022-11-28T12:43:47.828226Z","iopub.status.idle":"2022-11-28T12:43:47.835535Z","shell.execute_reply.started":"2022-11-28T12:43:47.828190Z","shell.execute_reply":"2022-11-28T12:43:47.833977Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#now we will load our data\nimport torch\nfrom torchtext.vocab import GloVe\nembedding_glove = GloVe(name='6B', dim=300)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-28T12:43:49.564302Z","iopub.execute_input":"2022-11-28T12:43:49.564679Z","iopub.status.idle":"2022-11-28T12:47:44.682368Z","shell.execute_reply.started":"2022-11-28T12:43:49.564649Z","shell.execute_reply":"2022-11-28T12:47:44.681199Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":".vector_cache/glove.6B.zip: 862MB [02:43, 5.28MB/s]                               \n100%|█████████▉| 399999/400000 [00:45<00:00, 8830.70it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"from torchtext.data import get_tokenizer\ntokenizer = get_tokenizer('basic_english')\ntrain_x_data = ((pd.read_csv(train_x_path))['Title'])\ntrain_y_data = ((pd.read_csv(train_y_path))['Genre']).to_numpy()\ntest_x_data = ((pd.read_csv(test_x_path))['Title'])\ntest_y_data = ((pd.read_csv(test_y_path))['Genre']).to_numpy()\ndevice = \"cpu\"\nprint(f\"Using {device} device\")\nbatch_size = 300\nembedding_size = 10\ndef tokenize(data,max_length):\n    total_points = len(data)\n    final_dataset = torch.zeros([total_points,max_length,300]).to(device)\n    for point in range(total_points):\n        sentence = data[point]\n        word_list = tokenizer(sentence)\n        value = embedding_glove.get_vecs_by_tokens(word_list)\n        total_words = len(word_list)\n        if total_words >= max_length:\n            final_dataset[point,:,:] = value[0:max_length,:]\n        else:\n            final_dataset[point,:total_words,:] = value\n    return final_dataset\ntrain_embedding = tokenize(train_x_data,embedding_size)\ntest_embedding = tokenize(test_x_data,embedding_size)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T12:48:10.548899Z","iopub.execute_input":"2022-11-28T12:48:10.552463Z","iopub.status.idle":"2022-11-28T12:48:13.975333Z","shell.execute_reply.started":"2022-11-28T12:48:10.552371Z","shell.execute_reply":"2022-11-28T12:48:13.974152Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Using cpu device\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim","metadata":{"execution":{"iopub.status.busy":"2022-11-28T12:48:17.501877Z","iopub.execute_input":"2022-11-28T12:48:17.502417Z","iopub.status.idle":"2022-11-28T12:48:17.509209Z","shell.execute_reply.started":"2022-11-28T12:48:17.502371Z","shell.execute_reply":"2022-11-28T12:48:17.507698Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class BidirectionalRNN(nn.Module):\n    def __init__(self,input_size,hidden_size,num_layers,total_classes,sequence_length):\n        super(BidirectionalRNN,self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.total_classes = total_classes\n        self.sequence_length = sequence_length\n        self.bidirectionalRNN = nn.RNN(input_size,hidden_size,num_layers,batch_first = True,bidirectional = True)\n        #we will put the context vector as input\n        self.fc1 = nn.Linear(2*hidden_size,128)\n        self.fc2 = nn.Linear(128,total_classes)\n    def forward(self,x):\n        batch_size = x.size(0)\n        h0 = torch.zeros([2*self.num_layers,batch_size,self.hidden_size],dtype= torch.float).to(device)\n        output,final_hidden = self.bidirectionalRNN(x,h0)\n        output = self.fc1(output[:,-1,:])\n        output = (nn.Tanh())(output)\n        output = self.fc2(output)\n        return output\nneural_net = BidirectionalRNN(300,128,1,30,embedding_size).to(device)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T12:49:05.712893Z","iopub.execute_input":"2022-11-28T12:49:05.713545Z","iopub.status.idle":"2022-11-28T12:49:05.734047Z","shell.execute_reply.started":"2022-11-28T12:49:05.713494Z","shell.execute_reply":"2022-11-28T12:49:05.732762Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss()\nepochs = 25\nlearning_rate = 0.0006\noptimizer = optim.Adam(neural_net.parameters(), lr = learning_rate)\nneural_net.zero_grad()","metadata":{"execution":{"iopub.status.busy":"2022-11-28T12:49:10.925912Z","iopub.execute_input":"2022-11-28T12:49:10.926424Z","iopub.status.idle":"2022-11-28T12:49:10.934342Z","shell.execute_reply.started":"2022-11-28T12:49:10.926387Z","shell.execute_reply":"2022-11-28T12:49:10.933072Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def accuracy(input,output):\n    prediction = neural_net(input)\n    points = len(output)\n    correct = 0\n    for i in range(points):\n        index = torch.argmax(prediction[i,:])\n        if index == output[i]:\n            correct += 1\n    return (100*correct)/(points)\ndef train_model():\n    total_points = train_embedding.size(0)\n    for i in range(epochs):\n        for j in range(0,total_points,batch_size):\n            target = 0\n            data_points = 0\n            if j + batch_size <= total_points:\n                data_points = train_embedding[j:(j+batch_size),:,:]\n                target = torch.tensor(train_y_data[j:j+batch_size]).to(device)\n            else:\n                data_points = train_embedding[j:,:,:]\n                target = torch.tensor(train_y_data[j:]).to(device)\n            optimizer.zero_grad()\n            output = neural_net(data_points).to(device)\n            loss = loss_fn(output, target)\n            loss.backward()\n            optimizer.step()\ntrain_model()\nprint(f\"Train accuracy after epoch {epochs} is {accuracy(train_embedding,train_y_data)}\")\nprint(f\"Test accuracy after epoch {epochs} is {accuracy (test_embedding,test_y_data)}\")\nprint('Training Complete!')","metadata":{"execution":{"iopub.status.busy":"2022-11-28T12:50:31.720022Z","iopub.execute_input":"2022-11-28T12:50:31.720618Z","iopub.status.idle":"2022-11-28T12:51:51.656218Z","shell.execute_reply.started":"2022-11-28T12:50:31.720580Z","shell.execute_reply":"2022-11-28T12:51:51.654752Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Train accuracy after epoch 25 is 57.71637426900585\nTest accuracy after epoch 25 is 43.80701754385965\nTraining Complete!\n","output_type":"stream"}]},{"cell_type":"code","source":"comp_test = tokenize(test_x_data,embedding_size)\npredictions = neural_net(comp_test)\ndef output_file_creator(predictions):\n    id_value = []\n    genre = []\n    points = predictions.size(0)\n    for i in range(points):\n        id_value.append(i)\n        index = torch.argmax(predictions[i,:])\n        genre.append(index.item())\n    dictCsv = {'Id' : id_value,'Genre':genre}\n    df1 = pd.DataFrame(dictCsv)\n    df1.to_csv('non_comp_test_pred_y.csv',index = False)\noutput_file_creator(predictions)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T12:54:10.502373Z","iopub.execute_input":"2022-11-28T12:54:10.502838Z","iopub.status.idle":"2022-11-28T12:54:11.210020Z","shell.execute_reply.started":"2022-11-28T12:54:10.502803Z","shell.execute_reply":"2022-11-28T12:54:11.208724Z"},"trusted":true},"execution_count":11,"outputs":[]}]}